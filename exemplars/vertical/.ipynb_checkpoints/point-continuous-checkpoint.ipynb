{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de18513-ce8b-406b-88a8-772efd0bb0a3",
   "metadata": {},
   "source": [
    "# ```sampley``` exemplar: the point approach\n",
    "Before going through this exemplar, please consult the Introduction to sampley exemplars (```intro.ipynb```).\n",
    "<br>This exemplar illustrates an application of the point approach to data contained within a single file (```trackpoints.csv```) containing continuous datapoints (i.e., datapoints recorded at frequent, regular intervals) that can be joined to construct survey tracks.\n",
    "<br>It differs from the standard point exemplar as having continuous datapoints allows for certain procedures to be applied in Stage 3 that may be more efficient and precise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f17978-8542-4d78-b4ac-cf397fc1a02d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060e52d-229d-459d-b1cf-f2fe092a266a",
   "metadata": {},
   "source": [
    "### Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c26ed0-1dff-4b75-bcf2-0595373e7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampley import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c681985-ba89-48a9-b39f-8cdd41760bbb",
   "metadata": {},
   "source": [
    "### Set the input folder\n",
    "To run this exemplar, download the mock data files, put them in a folder, and set the path to the folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aca9bb-d9e0-4af9-b903-4180094dab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = './input/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b329d-dc56-447b-b07d-6895e04cf73d",
   "metadata": {},
   "source": [
    "### Set the output folder\n",
    "To run this exemplar, make a folder to save the outputs in and set the path to the folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8e9468-4c66-4b7b-a323-0164ae0c08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a09925-bf1c-42ca-85a4-d0bccf0a8d43",
   "metadata": {},
   "source": [
    "## Stage 1\n",
    "In Stage 1, we import a single file (```trackpoints.csv```) to make a ```DataPoints``` object, from which we then make a ```Sections``` object.\n",
    "<br>Although we use a CSV file in this exemplar, there are other options for file types (including XLSX, GPKG, and SHP files). Please see the Stage 1 exemplar (```stage-1.ipynb```) in the horizontal exemplars folder or the User Manual for more details. Note that, regardless of the input file type, once any ```DataPoints``` and/or ```Sections``` objects have been made, the subsequent processing will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43d348ba-dc97-48a6-9c1b-3a7754ada0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: file successfully input.\n",
      "Success: x and y (lon/lat) coordinates successfully parsed.\n",
      "Success: reprojected to CRS 'EPSG:32619'\n",
      "Success: the column 'datetime' successfully reformatted to datetimes.\n",
      "Success: the timezone of column 'datetime' successfully set to 'UTC-05:00'.\n",
      "Success: datapoint IDs successfully generated.\n"
     ]
    }
   ],
   "source": [
    "u_trackpoints = DataPoints.from_file(\n",
    "    filepath=input_folder+'trackpoints.csv',\n",
    "    x_col='lon',\n",
    "    y_col='lat',\n",
    "    crs_input='EPSG:4326',\n",
    "    crs_working='EPSG:32619',\n",
    "    datetime_col='datetime',\n",
    "    tz_input='UTC-05:00',\n",
    "    section_id_col='section_id'  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a009720-1548-4f10-b858-39d8ef4b6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_sections = Sections.from_datapoints(datapoints=u_trackpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27b45e-4de2-441c-9422-78e44117cceb",
   "metadata": {},
   "source": [
    "## Stage 2\n",
    "In Stage 2, we use the ```DataPoints``` object containing sightings data to make a ```Presences``` object which we thin with a spatial threshold of 10000 m and a temporal threshold of 5 days.\n",
    "<br>Then, we use that ```Presences``` object and the ```Sections``` object to make an ```AbsenceLines``` object with the same thresholds.\n",
    "<br>Finally, we use the ```AbsenceLines``` object to make an ```Absences``` object which we also thin with the same thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3c0931-4bd2-4312-963d-ecc2959b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_presences = Presences.delimit(\n",
    "    datapoints=u_trackpoints,\n",
    "    presence_col='individuals')\n",
    "u_presences.thin(\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da055c7-e1d2-40df-b31f-dc0f5c913076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: absence lines to be generated with a temporal threshold of 5 day(s).\n"
     ]
    }
   ],
   "source": [
    "u_absencelines = AbsenceLines.delimit(\n",
    "    sections=u_sections,\n",
    "    presences=u_presences,\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093493d9-d8da-43c7-af4d-2bd3d60d4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_absences = Absences.delimit(\n",
    "    absencelines=u_absencelines,\n",
    "    var='along',\n",
    "    target=20,\n",
    "    dfls=None)\n",
    "u_absences.thin(\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day',\n",
    "    target=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6279b83-729a-4da0-b5e2-b749949181e2",
   "metadata": {},
   "source": [
    "## Stage 3\n",
    "In Stage 3, we make a ```Samples``` object from the ```DataPoints``` object, the ```Presences``` object, the ```Absences``` object, and the ```Sections``` object.\n",
    "<br>_Note that, as the absence lines are made from sections that are made from datapoints, we can match those datapoints to the absences by their distance from the beginning of the absences lines in order to give values to the absences. To do so we must input the sections (```sections=u_sections```)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143c6565-1cf6-418a-8392-d3f312d557eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_samples = Samples.point(\n",
    "    datapoints=u_trackpoints,\n",
    "    presences=u_presences,\n",
    "    absences=u_absences,\n",
    "    cols=['individuals', 'bss'],\n",
    "    sections=u_sections)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764faf10-00ae-4a44-afee-ed522b6c038c",
   "metadata": {},
   "source": [
    "## Output\n",
    "Finally, we save the ```Samples``` object to the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8fa530e-3dff-4e3b-9ea9-e027cdd241f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_samples.save(\n",
    "    folder=output_folder,\n",
    "    filetype='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39c7a43-9bf0-4d46-8d51-3f9468a18c2a",
   "metadata": {},
   "source": [
    "In the output folder, there should be two new CSVs: the first should have the same name as the ```Samples``` object (run the box below to see the name) while the second should also have this name but with ```-parameters``` added at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acb12d13-553d-4f1e-ac6e-579dafb2cc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samples-presences-trackpoints-+-absences-a-10000m-5day'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748c5e4a-c72a-47b9-abae-c4902f7d6974",
   "metadata": {},
   "source": [
    "The first CSV should contain the samples, like those shown in the box below. \n",
    "<br>In this dataframe, each row represents a given presence or absence, i.e., a sample. \n",
    "<br>The column ```point``` delimits the location of the presence/absence.\n",
    "<br>At the end are the data columns. In this particular example, they are ```p-a``` (presence-absence), ```individuals```, and ```bss```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "807f7168-a8a6-4297-a41a-476beb14b2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_id</th>\n",
       "      <th>point</th>\n",
       "      <th>date</th>\n",
       "      <th>datapoint_id</th>\n",
       "      <th>p-a</th>\n",
       "      <th>individuals</th>\n",
       "      <th>bss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p01</td>\n",
       "      <td>POINT (579166.78 4742872.701)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>d0004</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p03</td>\n",
       "      <td>POINT (548599.876 4742700.214)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>d0082</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p04</td>\n",
       "      <td>POINT (520909.741 4714855.058)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>d0480</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p05</td>\n",
       "      <td>POINT (532548.249 4714899.835)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>d0510</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p06</td>\n",
       "      <td>POINT (512817.407 4705582.465)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>d0910</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p08</td>\n",
       "      <td>POINT (654449.136 4716189.584)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1306</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p10</td>\n",
       "      <td>POINT (643532.681 4716066.52)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1336</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p11</td>\n",
       "      <td>POINT (629124.489 4706545.106)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1527</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p13</td>\n",
       "      <td>POINT (611976.857 4696974.111)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1739</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a01</td>\n",
       "      <td>POINT (527480.826 4742612.496)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>d0135</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a03</td>\n",
       "      <td>POINT (517367.603 4742588.391)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>d0162</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a18</td>\n",
       "      <td>POINT (569417.212 4733568.722)</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>d0260</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a20</td>\n",
       "      <td>POINT (534677.681 4733417.991)</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>d0342</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a06</td>\n",
       "      <td>POINT (569159.993 4715094.544)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>d0602</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a07</td>\n",
       "      <td>POINT (620277.079 4734156.111)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1080</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a10</td>\n",
       "      <td>POINT (650344.782 4725468.429)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1261</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a13</td>\n",
       "      <td>POINT (602732.935 4710901.419)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1456</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a14</td>\n",
       "      <td>POINT (650240.574 4697655.471)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d1632</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_id                           point       date datapoint_id  p-a  \\\n",
       "0       p01   POINT (579166.78 4742872.701) 2019-01-25        d0004    1   \n",
       "1       p03  POINT (548599.876 4742700.214) 2019-01-25        d0082    1   \n",
       "2       p04  POINT (520909.741 4714855.058) 2019-02-02        d0480    1   \n",
       "3       p05  POINT (532548.249 4714899.835) 2019-02-02        d0510    1   \n",
       "4       p06  POINT (512817.407 4705582.465) 2019-02-02        d0910    1   \n",
       "5       p08  POINT (654449.136 4716189.584) 2019-02-05        d1306    1   \n",
       "6       p10   POINT (643532.681 4716066.52) 2019-02-05        d1336    1   \n",
       "7       p11  POINT (629124.489 4706545.106) 2019-02-05        d1527    1   \n",
       "8       p13  POINT (611976.857 4696974.111) 2019-02-05        d1739    1   \n",
       "9       a01  POINT (527480.826 4742612.496) 2019-01-25        d0135    0   \n",
       "10      a03  POINT (517367.603 4742588.391) 2019-01-25        d0162    0   \n",
       "11      a18  POINT (569417.212 4733568.722) 2019-03-03        d0260    0   \n",
       "12      a20  POINT (534677.681 4733417.991) 2019-03-03        d0342    0   \n",
       "13      a06  POINT (569159.993 4715094.544) 2019-02-02        d0602    0   \n",
       "14      a07  POINT (620277.079 4734156.111) 2019-02-05        d1080    0   \n",
       "15      a10  POINT (650344.782 4725468.429) 2019-02-05        d1261    0   \n",
       "16      a13  POINT (602732.935 4710901.419) 2019-02-05        d1456    0   \n",
       "17      a14  POINT (650240.574 4697655.471) 2019-02-05        d1632    0   \n",
       "\n",
       "    individuals  bss  \n",
       "0           1.0    2  \n",
       "1           5.0    2  \n",
       "2           1.0    1  \n",
       "3           2.0    1  \n",
       "4           1.0    1  \n",
       "5           5.0    1  \n",
       "6           1.0    2  \n",
       "7           3.0    2  \n",
       "8           4.0    3  \n",
       "9           NaN    3  \n",
       "10          NaN    3  \n",
       "11          NaN    3  \n",
       "12          NaN    3  \n",
       "13          NaN    1  \n",
       "14          NaN    0  \n",
       "15          NaN    0  \n",
       "16          NaN    2  \n",
       "17          NaN    2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0706395c-8dd7-4669-a349-16922299575b",
   "metadata": {},
   "source": [
    "The second CSV should contain the parameters, like those shown in the box below (but arranged in a table). This information may prove useful if, later, we need to know  how the samples were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68055e08-f44b-44de-830c-dfbf23669ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approach': 'point',\n",
       " 'resampled': 'datapoints',\n",
       " 'presences_name': 'presences-trackpoints',\n",
       " 'presences_crs': 'EPSG:32619',\n",
       " 'presences_sp_threshold': 10000,\n",
       " 'presences_tm_threshold': 5,\n",
       " 'presences_tm_unit': 'day',\n",
       " 'absences_name': 'absences-a-10000m-5day',\n",
       " 'absences_var': 'along',\n",
       " 'absences_target': 20,\n",
       " 'absences_crs': 'EPSG:32619',\n",
       " 'absences_sp_threshold': 10000,\n",
       " 'absences_tm_threshold': 5,\n",
       " 'absences_tm_unit': 'day'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
