{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de18513-ce8b-406b-88a8-772efd0bb0a3",
   "metadata": {},
   "source": [
    "# ```sampley``` exemplar: the point approach\n",
    "Before going through this exemplar, please consult the Introduction to sampley exemplars (```intro.ipynb```).\n",
    "<br>This exemplar illustrates an application of the point approach to data contained within two files: one containing survey tracks (```sections.gpkg```) and one containing sightings data (```sightings.gpkg```)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f17978-8542-4d78-b4ac-cf397fc1a02d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060e52d-229d-459d-b1cf-f2fe092a266a",
   "metadata": {},
   "source": [
    "### Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c26ed0-1dff-4b75-bcf2-0595373e7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampley import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c681985-ba89-48a9-b39f-8cdd41760bbb",
   "metadata": {},
   "source": [
    "### Set the input folder\n",
    "To run this exemplar, download the mock data files, put them in a folder, and set the path to the folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aca9bb-d9e0-4af9-b903-4180094dab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = './input/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b329d-dc56-447b-b07d-6895e04cf73d",
   "metadata": {},
   "source": [
    "### Set the output folder\n",
    "To run this exemplar, make a folder to save the outputs in and set the path to the folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8e9468-4c66-4b7b-a323-0164ae0c08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a267934-417a-4d4c-ab9d-20056a678ea2",
   "metadata": {},
   "source": [
    "## Stage 1\n",
    "In Stage 1, we import two files (```sightings.csv``` and ```sections.gpkg```) and from them make a ```DataPoints``` and a ```Sections``` object, respectively.\n",
    "<br>Although we use a CSV file and a GPKG file in this exemplar, there are other options for file types (including XLSX and SHP files). Please see the Stage 1 exemplar (```stage-1.ipynb```) in the horizontal exemplars folder or the User Manual for more details. Note that, regardless of the input file type, once any ```DataPoints``` and/or ```Sections``` objects have been made, the subsequent processing will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f239273a-e22a-4d85-b4c5-995fc401a9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: file successfully input.\n",
      "Success: x and y (lon/lat) coordinates successfully parsed.\n",
      "Success: reprojected to CRS 'EPSG:32619'\n",
      "Success: the column 'datetime' successfully reformatted to datetimes.\n",
      "Success: the timezone of column 'datetime' successfully set to 'UTC-05:00'.\n",
      "Success: datapoint IDs successfully generated.\n"
     ]
    }
   ],
   "source": [
    "u_sightings = DataPoints.from_file(\n",
    "    filepath=input_folder+'sightings.csv',\n",
    "    x_col='lon',\n",
    "    y_col='lat',\n",
    "    crs_input='EPSG:4326',\n",
    "    crs_working='EPSG:32619',\n",
    "    datetime_col='datetime',\n",
    "    tz_input='UTC-05:00'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d117c9b-d09b-422a-bfe3-495ed65fe157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: file successfully input.\n",
      "Success: reprojected to CRS 'EPSG:32619'\n",
      "Success: the column 'datetime_beg' successfully reformatted to datetimes.\n",
      "Success: the timezone of column 'datetime_beg' successfully set to 'UTC-05:00'.\n",
      "Note: column 'datetime_beg' renamed to 'datetime'.\n",
      "Success: section IDs successfully generated.\n"
     ]
    }
   ],
   "source": [
    "u_sections = Sections.from_file(\n",
    "    filepath=input_folder+'sections.gpkg',\n",
    "    crs_working='EPSG:32619',\n",
    "    datetime_col='datetime_beg',\n",
    "    tz_input='UTC-05:00'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27b45e-4de2-441c-9422-78e44117cceb",
   "metadata": {},
   "source": [
    "## Stage 2\n",
    "In Stage 2, we use the ```DataPoints``` object containing sightings data to make a ```Presences``` object which we thin with a spatial threshold of 10000 m and a temporal threshold of 5 days.\n",
    "<br>Then, we use that ```Presences``` object and the ```Sections``` object to make an ```AbsenceLines``` object with the same thresholds.\n",
    "<br>Finally, we use the ```AbsenceLines``` object to make an ```Absences``` object which we also thin with the same thresholds as well as a target equal to the number of presences kept after thinning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3c0931-4bd2-4312-963d-ecc2959b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_presences = Presences.delimit(datapoints=u_sightings)\n",
    "u_presences.thin(\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da055c7-e1d2-40df-b31f-dc0f5c913076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: absence lines to be generated with a temporal threshold of 5 day(s).\n"
     ]
    }
   ],
   "source": [
    "u_absencelines = AbsenceLines.delimit(\n",
    "    sections=u_sections,\n",
    "    presences=u_presences,\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093493d9-d8da-43c7-af4d-2bd3d60d4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_absences = Absences.delimit(\n",
    "    absencelines=u_absencelines,\n",
    "    var='along',\n",
    "    target=20,\n",
    "    dfls=None)\n",
    "u_absences.thin(\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day',\n",
    "    target=len(u_presences.kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6279b83-729a-4da0-b5e2-b749949181e2",
   "metadata": {},
   "source": [
    "## Stage 3\n",
    "In Stage 3, we make a ```Samples``` object from the ```DataPoints``` object, the ```Presences``` object, and the ```Absences``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143c6565-1cf6-418a-8392-d3f312d557eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_samples = Samples.point(\n",
    "    datapoints=u_sightings,\n",
    "    presences=u_presences,\n",
    "    absences=u_absences,\n",
    "    cols=['individuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e2d08-f66c-47ff-9b27-83b90b8ae20a",
   "metadata": {},
   "source": [
    "## Output\n",
    "Finally, we save the ```Samples``` object to the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed14f8f3-65d9-4b2d-a704-740813810d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_samples.save(\n",
    "    folder=output_folder,\n",
    "    filetype='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dc37e-0b4e-484a-a1f5-94cc21294aa7",
   "metadata": {},
   "source": [
    "In the output folder, there should be two new CSVs: the first should have the same name as the ```Samples``` object (run the box below to see the name) while the second should also have this name but with ```-parameters``` added at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595973a0-464e-4417-a612-f77f5d563745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samples-presences-sightings-+-absences-a-10000m-5day'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177ea37-1381-41fa-896f-39a470ed35c3",
   "metadata": {},
   "source": [
    "The first CSV should contain the samples, like those shown in the box below. \n",
    "<br>In this dataframe, each row represents a given presence or absence, i.e., a sample. \n",
    "<br>The column ```point``` delimits the location of the presence/absence.\n",
    "<br>At the end are the data columns. In this particular example, they are ```p-a``` (presence-absence) and ```individuals```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea5f1e9a-64ca-48ac-9a2a-7c1b996ff940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_id</th>\n",
       "      <th>point</th>\n",
       "      <th>date</th>\n",
       "      <th>p-a</th>\n",
       "      <th>individuals</th>\n",
       "      <th>datapoint_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p01</td>\n",
       "      <td>POINT (579166.78 4742872.701)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>d01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p02</td>\n",
       "      <td>POINT (554184.217 4742741.886)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>d02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p04</td>\n",
       "      <td>POINT (520909.741 4714855.058)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>d04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p05</td>\n",
       "      <td>POINT (532548.249 4714899.835)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>d05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p07</td>\n",
       "      <td>POINT (504710.41 4705553.392)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>d07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p08</td>\n",
       "      <td>POINT (654449.136 4716189.584)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>d08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p10</td>\n",
       "      <td>POINT (643532.681 4716066.52)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>d10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p11</td>\n",
       "      <td>POINT (629124.489 4706545.106)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>d11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p13</td>\n",
       "      <td>POINT (611976.857 4696974.111)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>d13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a05</td>\n",
       "      <td>POINT (592083.534 4706006.136)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a07</td>\n",
       "      <td>POINT (578869.073 4705942.655)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a08</td>\n",
       "      <td>POINT (553110.688 4705791.975)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a11</td>\n",
       "      <td>POINT (606815.56 4733898.138)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a13</td>\n",
       "      <td>POINT (626014.426 4725001.89)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a14</td>\n",
       "      <td>POINT (610553.119 4715444.474)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a15</td>\n",
       "      <td>POINT (648549.794 4697637.088)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a17</td>\n",
       "      <td>POINT (569985.954 4733574.462)</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a20</td>\n",
       "      <td>POINT (540211.091 4733429.111)</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_id                           point       date  p-a  individuals  \\\n",
       "0       p01   POINT (579166.78 4742872.701) 2019-01-25    1          1.0   \n",
       "1       p02  POINT (554184.217 4742741.886) 2019-01-25    1          2.0   \n",
       "2       p04  POINT (520909.741 4714855.058) 2019-02-02    1          1.0   \n",
       "3       p05  POINT (532548.249 4714899.835) 2019-02-02    1          2.0   \n",
       "4       p07   POINT (504710.41 4705553.392) 2019-02-02    1          3.0   \n",
       "5       p08  POINT (654449.136 4716189.584) 2019-02-05    1          5.0   \n",
       "6       p10   POINT (643532.681 4716066.52) 2019-02-05    1          1.0   \n",
       "7       p11  POINT (629124.489 4706545.106) 2019-02-05    1          3.0   \n",
       "8       p13  POINT (611976.857 4696974.111) 2019-02-05    1          4.0   \n",
       "9       a05  POINT (592083.534 4706006.136) 2019-02-02    0          NaN   \n",
       "10      a07  POINT (578869.073 4705942.655) 2019-02-02    0          NaN   \n",
       "11      a08  POINT (553110.688 4705791.975) 2019-02-02    0          NaN   \n",
       "12      a11   POINT (606815.56 4733898.138) 2019-02-05    0          NaN   \n",
       "13      a13   POINT (626014.426 4725001.89) 2019-02-05    0          NaN   \n",
       "14      a14  POINT (610553.119 4715444.474) 2019-02-05    0          NaN   \n",
       "15      a15  POINT (648549.794 4697637.088) 2019-02-05    0          NaN   \n",
       "16      a17  POINT (569985.954 4733574.462) 2019-03-03    0          NaN   \n",
       "17      a20  POINT (540211.091 4733429.111) 2019-03-03    0          NaN   \n",
       "\n",
       "   datapoint_id  \n",
       "0           d01  \n",
       "1           d02  \n",
       "2           d04  \n",
       "3           d05  \n",
       "4           d07  \n",
       "5           d08  \n",
       "6           d10  \n",
       "7           d11  \n",
       "8           d13  \n",
       "9           NaN  \n",
       "10          NaN  \n",
       "11          NaN  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14          NaN  \n",
       "15          NaN  \n",
       "16          NaN  \n",
       "17          NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c05c6-6757-4aea-bfe7-247d73eb306e",
   "metadata": {},
   "source": [
    "The second CSV should contain the parameters, like those shown in the box below (but arranged in a table). This information may prove useful if, later, we need to know  how the samples were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bbf5454-f754-4f76-8ac1-5fff9cfeee48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approach': 'point',\n",
       " 'resampled': 'datapoints',\n",
       " 'presences_name': 'presences-sightings',\n",
       " 'presences_crs': 'EPSG:32619',\n",
       " 'presences_sp_threshold': 10000,\n",
       " 'presences_tm_threshold': 5,\n",
       " 'presences_tm_unit': 'day',\n",
       " 'absences_name': 'absences-a-10000m-5day',\n",
       " 'absences_var': 'along',\n",
       " 'absences_target': 20,\n",
       " 'absences_crs': 'EPSG:32619',\n",
       " 'absences_sp_threshold': 10000,\n",
       " 'absences_tm_threshold': 5,\n",
       " 'absences_tm_unit': 'day'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
