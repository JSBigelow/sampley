{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de18513-ce8b-406b-88a8-772efd0bb0a3",
   "metadata": {},
   "source": [
    "# ```sampley``` exemplar: the point approach\n",
    "Before going through this exemplar, please consult the Introduction to sampley exemplars (```intro.ipynb```).\n",
    "<br>This exemplar illustrates an application of the point approach to data contained within two files: one containing survey tracks (```sections.gpkg```) and one containing sightings data (```sightings.gpkg```)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f17978-8542-4d78-b4ac-cf397fc1a02d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c060e52d-229d-459d-b1cf-f2fe092a266a",
   "metadata": {},
   "source": [
    "### Import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00c26ed0-1dff-4b75-bcf2-0595373e7743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sampley import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c681985-ba89-48a9-b39f-8cdd41760bbb",
   "metadata": {},
   "source": [
    "### Set the input folder\n",
    "To run this exemplar, download the mock data files, put them in a folder, and set the path to the folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90aca9bb-d9e0-4af9-b903-4180094dab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = './input/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887b329d-dc56-447b-b07d-6895e04cf73d",
   "metadata": {},
   "source": [
    "### Set the output folder\n",
    "To run this exemplar, make a folder to save the outputs in and set the path to the folder below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad8e9468-4c66-4b7b-a323-0164ae0c08eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a267934-417a-4d4c-ab9d-20056a678ea2",
   "metadata": {},
   "source": [
    "## Stage 1\n",
    "In Stage 1, we import two files (```sightings.csv``` and ```sections.gpkg```) and from them make a ```DataPoints``` and a ```Sections``` object, respectively.\n",
    "<br>Although we use a CSV file and a GPKG file in this exemplar, there are other options for file types (including XLSX and SHP files). Please see the Stage 1 exemplar (```stage-1.ipynb```) in the horizontal exemplars folder or the User Manual for more details. Note that, regardless of the input file type, once any ```DataPoints``` and/or ```Sections``` objects have been made, the subsequent processing will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f239273a-e22a-4d85-b4c5-995fc401a9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: file successfully input.\n",
      "Success: x and y (lon/lat) coordinates successfully parsed.\n",
      "Success: reprojected to CRS 'EPSG:32619'\n",
      "Success: the column 'datetime' successfully reformatted to datetimes.\n",
      "Success: the timezone of column 'datetime' successfully set to 'UTC-05:00'.\n",
      "Success: datapoint IDs successfully generated.\n"
     ]
    }
   ],
   "source": [
    "u_sightings = DataPoints.from_file(\n",
    "    filepath=input_folder+'sightings.csv',\n",
    "    x_col='lon',\n",
    "    y_col='lat',\n",
    "    crs_input='EPSG:4326',\n",
    "    crs_working='EPSG:32619',\n",
    "    datetime_col='datetime',\n",
    "    tz_input='UTC-05:00'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d117c9b-d09b-422a-bfe3-495ed65fe157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: file successfully input.\n",
      "Success: reprojected to CRS 'EPSG:32619'\n",
      "Success: the column 'datetime_beg' successfully reformatted to datetimes.\n",
      "Success: the timezone of column 'datetime_beg' successfully set to 'UTC-05:00'.\n",
      "Note: column 'datetime_beg' renamed to 'datetime'.\n",
      "Success: section IDs successfully generated.\n"
     ]
    }
   ],
   "source": [
    "u_sections = Sections.from_file(\n",
    "    filepath=input_folder+'sections.gpkg',\n",
    "    crs_working='EPSG:32619',\n",
    "    datetime_col='datetime_beg',\n",
    "    tz_input='UTC-05:00'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27b45e-4de2-441c-9422-78e44117cceb",
   "metadata": {},
   "source": [
    "## Stage 2\n",
    "In Stage 2, we use the ```DataPoints``` object containing sightings data to make a ```Presences``` object which we thin with a spatial threshold of 10000 m and a temporal threshold of 5 days.\n",
    "<br>Then, we use that ```Presences``` object and the ```Sections``` object to make an ```AbsenceLines``` object with the same thresholds.\n",
    "<br>Finally, we use the ```AbsenceLines``` object to make an ```Absences``` object which we also thin with the same thresholds as well as a target equal to the number of presences kept after thinning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3c0931-4bd2-4312-963d-ecc2959b2c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_presences = Presences.delimit(datapoints=u_sightings)\n",
    "u_presences.thin(\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da055c7-e1d2-40df-b31f-dc0f5c913076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: absence lines to be generated with a temporal threshold of 5 day(s).\n"
     ]
    }
   ],
   "source": [
    "u_absencelines = AbsenceLines.delimit(\n",
    "    sections=u_sections,\n",
    "    presences=u_presences,\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "093493d9-d8da-43c7-af4d-2bd3d60d4f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_absences = Absences.delimit(\n",
    "    absencelines=u_absencelines,\n",
    "    var='along',\n",
    "    target=20)\n",
    "u_absences.thin(\n",
    "    sp_threshold=10000,\n",
    "    tm_threshold=5,\n",
    "    tm_unit='day',\n",
    "    target=len(u_presences.kept))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6279b83-729a-4da0-b5e2-b749949181e2",
   "metadata": {},
   "source": [
    "## Stage 3\n",
    "In Stage 3, we make a ```Samples``` object from the ```DataPoints``` object, the ```Presences``` object, and the ```Absences``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "143c6565-1cf6-418a-8392-d3f312d557eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_samples = Samples.point(\n",
    "    datapoints=u_sightings,\n",
    "    presences=u_presences,\n",
    "    absences=u_absences,\n",
    "    cols=['individuals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8e2d08-f66c-47ff-9b27-83b90b8ae20a",
   "metadata": {},
   "source": [
    "## Output\n",
    "Finally, we save the ```Samples``` object to the output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed14f8f3-65d9-4b2d-a704-740813810d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_samples.save(\n",
    "    folder=output_folder,\n",
    "    filetype='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dc37e-0b4e-484a-a1f5-94cc21294aa7",
   "metadata": {},
   "source": [
    "In the output folder, there should be two new CSVs: the first should have the same name as the ```Samples``` object (run the box below to see the name) while the second should also have this name but with ```-parameters``` added at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595973a0-464e-4417-a612-f77f5d563745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'samples-presences-sightings-+-absences-a-10000m-5day'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9177ea37-1381-41fa-896f-39a470ed35c3",
   "metadata": {},
   "source": [
    "The first CSV should contain the samples, like those shown in the box below. \n",
    "<br>In this dataframe, each row represents a given presence or absence, i.e., a sample. \n",
    "<br>The column ```point``` delimits the location of the presence/absence.\n",
    "<br>At the end are the data columns. In this particular example, they are ```p-a``` (presence-absence) and ```individuals```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea5f1e9a-64ca-48ac-9a2a-7c1b996ff940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>point_id</th>\n",
       "      <th>point</th>\n",
       "      <th>date</th>\n",
       "      <th>datapoint_id</th>\n",
       "      <th>p-a</th>\n",
       "      <th>individuals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p01</td>\n",
       "      <td>POINT (579166.78 4742872.701)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>d01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p03</td>\n",
       "      <td>POINT (548599.876 4742700.214)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>d03</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p04</td>\n",
       "      <td>POINT (520909.741 4714855.058)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>d04</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p05</td>\n",
       "      <td>POINT (532548.249 4714899.835)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>d05</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p07</td>\n",
       "      <td>POINT (504710.41 4705553.392)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>d07</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p08</td>\n",
       "      <td>POINT (654449.136 4716189.584)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d08</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>p10</td>\n",
       "      <td>POINT (643532.681 4716066.52)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>p11</td>\n",
       "      <td>POINT (629124.489 4706545.106)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d11</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>p13</td>\n",
       "      <td>POINT (611976.857 4696974.111)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>d13</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a01</td>\n",
       "      <td>POINT (528139.94 4742605.103)</td>\n",
       "      <td>2019-01-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a04</td>\n",
       "      <td>POINT (583944.739 4715164.174)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a06</td>\n",
       "      <td>POINT (556712.279 4705820.358)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a07</td>\n",
       "      <td>POINT (542908.773 4705758.32)</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a10</td>\n",
       "      <td>POINT (602418.31 4727522.56)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a12</td>\n",
       "      <td>POINT (634316.752 4725157.922)</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>a15</td>\n",
       "      <td>POINT (585684.025 4733659.189)</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a17</td>\n",
       "      <td>POINT (537417.904 4733432.294)</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>a19</td>\n",
       "      <td>POINT (520569.651 4733342.69)</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   point_id                           point       date datapoint_id  p-a  \\\n",
       "0       p01   POINT (579166.78 4742872.701) 2019-01-25          d01    1   \n",
       "1       p03  POINT (548599.876 4742700.214) 2019-01-25          d03    1   \n",
       "2       p04  POINT (520909.741 4714855.058) 2019-02-02          d04    1   \n",
       "3       p05  POINT (532548.249 4714899.835) 2019-02-02          d05    1   \n",
       "4       p07   POINT (504710.41 4705553.392) 2019-02-02          d07    1   \n",
       "5       p08  POINT (654449.136 4716189.584) 2019-02-05          d08    1   \n",
       "6       p10   POINT (643532.681 4716066.52) 2019-02-05          d10    1   \n",
       "7       p11  POINT (629124.489 4706545.106) 2019-02-05          d11    1   \n",
       "8       p13  POINT (611976.857 4696974.111) 2019-02-05          d13    1   \n",
       "9       a01   POINT (528139.94 4742605.103) 2019-01-25          NaN    0   \n",
       "10      a04  POINT (583944.739 4715164.174) 2019-02-02          NaN    0   \n",
       "11      a06  POINT (556712.279 4705820.358) 2019-02-02          NaN    0   \n",
       "12      a07   POINT (542908.773 4705758.32) 2019-02-02          NaN    0   \n",
       "13      a10    POINT (602418.31 4727522.56) 2019-02-05          NaN    0   \n",
       "14      a12  POINT (634316.752 4725157.922) 2019-02-05          NaN    0   \n",
       "15      a15  POINT (585684.025 4733659.189) 2019-03-03          NaN    0   \n",
       "16      a17  POINT (537417.904 4733432.294) 2019-03-03          NaN    0   \n",
       "17      a19   POINT (520569.651 4733342.69) 2019-03-03          NaN    0   \n",
       "\n",
       "    individuals  \n",
       "0           1.0  \n",
       "1           5.0  \n",
       "2           1.0  \n",
       "3           2.0  \n",
       "4           3.0  \n",
       "5           5.0  \n",
       "6           1.0  \n",
       "7           3.0  \n",
       "8           4.0  \n",
       "9           NaN  \n",
       "10          NaN  \n",
       "11          NaN  \n",
       "12          NaN  \n",
       "13          NaN  \n",
       "14          NaN  \n",
       "15          NaN  \n",
       "16          NaN  \n",
       "17          NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c05c6-6757-4aea-bfe7-247d73eb306e",
   "metadata": {},
   "source": [
    "The second CSV should contain the parameters, like those shown in the box below (but arranged in a table). This information may prove useful if, later, we need to know  how the samples were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bbf5454-f754-4f76-8ac1-5fff9cfeee48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'approach': 'point',\n",
       " 'resampled': 'datapoints',\n",
       " 'presences_name': 'presences-sightings',\n",
       " 'presences_crs': 'EPSG:32619',\n",
       " 'presences_sp_threshold': 10000,\n",
       " 'presences_tm_threshold': 5,\n",
       " 'presences_tm_unit': 'day',\n",
       " 'absences_name': 'absences-a-10000m-5day',\n",
       " 'absences_var': 'along',\n",
       " 'absences_target': 20,\n",
       " 'absences_crs': 'EPSG:32619',\n",
       " 'absences_sp_threshold': 10000,\n",
       " 'absences_tm_threshold': 5,\n",
       " 'absences_tm_unit': 'day'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_samples.parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
